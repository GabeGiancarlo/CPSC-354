\documentclass{article}

\usepackage{tikz} 
\usetikzlibrary{automata, positioning, arrows} 

\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{color}
\usepackage{parskip}
\usepackage{hyperref}
  \hypersetup{
    colorlinks = true,
    urlcolor = blue,       % color of external links using \href
    linkcolor= blue,       % color of internal links 
    citecolor= blue,       % color of links to bibliography
    filecolor= blue,        % color of file links
    }
    
\usepackage{listings}
\usepackage[utf8]{inputenc}                                                    
\usepackage[T1]{fontenc}                                                       

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=haskell,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\theoremstyle{plain} 
   \newtheorem{theorem}{Theorem}[section]
   \newtheorem{corollary}[theorem]{Corollary}
   \newtheorem{lemma}[theorem]{Lemma}
   \newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
   \newtheorem{definition}[theorem]{Definition}
   \newtheorem{example}[theorem]{Example}
\theoremstyle{remark}    
  \newtheorem{remark}[theorem]{Remark}

\title{CPSC-354 Report}
\author{Gabriel Giancarlo \\ Chapman University}

\date{\today} 

\begin{document}

\maketitle

\begin{abstract}
This comprehensive report documents my work throughout CPSC-354 Programming Languages course, covering formal systems, string rewriting, termination analysis, lambda calculus, and parsing theory. The assignments demonstrate progression from basic formal systems through advanced functional programming concepts, providing insight into the mathematical foundations of programming languages and computation.
\end{abstract}

\setcounter{tocdepth}{3}
\tableofcontents

\section{Introduction}\label{intro}

This report consolidates my work from CPSC-354 Programming Languages course, covering seven weeks of assignments that explore the mathematical foundations of programming languages. The course progression takes us from basic formal systems through advanced functional programming concepts, demonstrating how theoretical computer science principles underpin practical programming language design and implementation.

The assignments cover:
\begin{itemize}
\item \textbf{Week 1:} The MU Puzzle - Introduction to formal systems and invariants
\item \textbf{Week 2:} String Rewriting Systems - Abstract reduction systems and algorithm specification
\item \textbf{Week 3:} Termination Analysis - Measure functions and algorithm correctness
\item \textbf{Week 4:} Lambda Calculus - Functional programming foundations
\item \textbf{Week 5:} Lambda Calculus Workout - Advanced function composition
\item \textbf{Week 6:} Advanced Lambda Calculus - Church numerals, booleans, and recursion
\item \textbf{Week 7:} Parsing and Context-Free Grammars - Syntax analysis and compiler theory
\item \textbf{Natural Number Game:} Formal verification with Lean - Bridge between natural language and formal proof systems
\item \textbf{Lean Logic Game:} Propositional logic with Lean - Implication tutorial demonstrating constructive logic and proof terms
\end{itemize}

Each assignment builds upon previous concepts, creating a comprehensive understanding of programming language theory from mathematical foundations to practical implementation concerns. The Natural Number Game section demonstrates how formal verification systems can capture mathematical reasoning while maintaining computational rigor. The Lean Logic Game section explores propositional logic through the lens of constructive mathematics, where proofs are programs and implications are functions.

\section{Week by Week}\label{homework}

\subsection{Week 1: The MU Puzzle}

\subsubsection{Problem Statement}

The MU puzzle is a formal system with the following rules:
\begin{enumerate}
\item If a string ends with I, you can add U to the end
\item If you have Mx, you can add x to get Mxx
\item If you have III, you can replace it with U
\item If you have UU, you can delete it
\end{enumerate}

Starting with the string "MI", the question is: can you derive "MU"?

\subsubsection{Analysis}

To solve this puzzle, I need to analyze what strings are derivable from "MI" using the given rules. Let me trace through some possible derivations:

Starting with MI:
\begin{itemize}
\item MI → MIU (Rule 1: add U to end)
\item MIU → MIUIU (Rule 2: Mx → Mxx, where x = IU)
\item MIUIU → MIUIUIU (Rule 2 again)
\end{itemize}

I can continue this process, but I notice something important: the number of I's in the string.

\subsubsection{The Key Insight: Invariants}

The crucial observation is that the number of I's in the string is always congruent to 1 modulo 3. Let me prove this:

\begin{proof}
Let $n_I$ be the number of I's in the string. We start with MI, so $n_I = 1 \equiv 1 \pmod{3}$.

Now consider each rule:
\begin{itemize}
\item Rule 1 (I → IU): $n_I$ remains unchanged
\item Rule 2 (Mx → Mxx): $n_I$ doubles, so if $n_I \equiv 1 \pmod{3}$, then $2n_I \equiv 2 \pmod{3}$
\item Rule 3 (III → U): $n_I$ decreases by 3, so $n_I - 3 \equiv n_I \pmod{3}$
\item Rule 4 (UU → ε): $n_I$ remains unchanged
\end{itemize}

Since we start with $n_I \equiv 1 \pmod{3}$ and all rules preserve this property, we can never reach a string with $n_I \equiv 0 \pmod{3}$.

But MU has $n_I = 0$, so $n_I \equiv 0 \pmod{3}$.
\end{proof}

\subsubsection{Conclusion}

Since MU has 0 I's (which is congruent to 0 modulo 3), and we can never reach a string with 0 I's from MI (which has 1 I), it is impossible to derive MU from MI using the given rules.

\subsection{Week 2: String Rewriting Systems}

\subsubsection{Exercise 1: Basic Sorting}

The rewrite rule is:
\[
    ba \to ab
\]

\textbf{Why does the ARS terminate?}
The system always terminates because every time we apply the rule, the letters get closer to being in the correct order. There are only a limited number of ways to reorder a finite string, so eventually no more rules can be applied.

\textbf{What is the result of a computation (the normal form)?}
The normal form is the string where all the \texttt{a}'s come before all the \texttt{b}'s. For example, starting with \texttt{baba} we eventually reach \texttt{aabb}.

\textbf{Show that the result is unique (the ARS is confluent).}
Yes, the result is unique. No matter how we choose to apply the rule, we always end up with the same final string: all the \texttt{a}'s on the left and all the \texttt{b}'s on the right. This shows the system is confluent.

\textbf{What specification does this algorithm implement?}
This algorithm basically sorts the string by moving all the \texttt{a}'s to the left and the \texttt{b}'s to the right. In other words, it implements a simple sorting process.

\subsubsection{Exercise 2: Parity Computation}

The rewrite rules are:
\[
\texttt{aa} \to \texttt{a},\qquad
\texttt{bb} \to \texttt{a},\qquad
\texttt{ab} \to \texttt{b},\qquad
\texttt{ba} \to \texttt{b}.
\]

\begin{enumerate}[label=(\alph*)]
  \item \textbf{Why does the ARS terminate?}
  
  Every rule replaces two adjacent letters by a single letter, so each rewrite step strictly decreases the length of the word by exactly $1$. Since words are finite, you can't keep shortening forever. Therefore every rewrite sequence must stop after finitely many steps, so the ARS terminates.
  
  \item \textbf{What are the normal forms?}
  
  Because each step reduces length by $1$, any normal form must be a word that cannot be shortened further. The only words of length $1$ are \texttt{a} and \texttt{b}, and they contain no length-$2$ substring to rewrite, so they are normal. There are no other normal forms (every word of length $\ge 2$ has some adjacent pair and so admits a rewrite), hence the normal forms are exactly
  \[
    \texttt{a}\quad\text{and}\quad\texttt{b}.
  \]
  
  \item \textbf{Is there a string \(s\) that reduces to both \texttt{a} and \texttt{b}?}
  
  No. Intuitively, the rules preserve whether the number of \texttt{b}'s is even or odd (see part (d)), and \texttt{a} has zero \texttt{b}'s (even) while \texttt{b} has one \texttt{b} (odd). So a given input cannot end up as both \texttt{a} and \texttt{b}. Concretely: since the system terminates and every input has at least one normal form, and because an invariant (parity of \#\texttt{b}'s) distinguishes \texttt{a} from \texttt{b}, no string can reduce to both.
  
  \item \textbf{Show that the ARS is confluent.}
  
  We use the invariant ``number of \texttt{b}'s modulo $2$'' to argue confluence together with termination.
  
  \begin{itemize}
    \item Check the invariant: each rule changes the string locally but does not change the parity of the number of \texttt{b}'s.
      \begin{itemize}
        \item $\texttt{aa}\to\texttt{a}$: number of \texttt{b}'s unchanged (both sides have 0 \texttt{b}'s).
        \item $\texttt{bb}\to\texttt{a}$: two \texttt{b}'s are removed, so \#\texttt{b} decreases by $2$ (parity unchanged).
        \item $\texttt{ab}\to\texttt{b}$ and $\texttt{ba}\to\texttt{b}$: before there is exactly one \texttt{b}, after there is one \texttt{b} (parity unchanged).
      \end{itemize}
    \item By termination, every word rewrites in finitely many steps to some normal form (either \texttt{a} or \texttt{b}). Because parity of \#\texttt{b} is invariant, a word with even \#\texttt{b} cannot reach \texttt{b} (which has odd \#\texttt{b}) and a word with odd \#\texttt{b} cannot reach \texttt{a}. So each input has exactly one possible normal form determined by that parity.
  \end{itemize}
  
  Termination plus the fact that every input has a unique normal form implies confluence (there can't be two different normal forms reachable from the same input). So the ARS is confluent.
  
  \item \textbf{Which words become equal if we replace `$\to$' by `$=$`?}
  
  If we let `$=$` be the equivalence relation generated by the rewrite rules, then two words are equivalent exactly when they have the same parity of \texttt{b}'s. In other words:
  \[
    u = v \quad\Longleftrightarrow\quad |u|_{\texttt{b}} \equiv |v|_{\texttt{b}} \pmod{2}.
  \]
  So there are exactly two equivalence classes: the class of words with an even number of \texttt{b}'s (these are all equivalent to \texttt{a}) and the class of words with an odd number of \texttt{b}'s (these are all equivalent to \texttt{b}).
  
  \item \textbf{Characterise the equality abstractly / using modular arithmetic / final specification.}
  
  An abstract (implementation-free) description is: the system computes the parity of the number of \texttt{b}'s in the input word. If the number of \texttt{b}'s is even, the output is \texttt{a}; if it is odd, the output is \texttt{b}.
  
  A modular-arithmetic formulation: identify \texttt{a} with $0$ and \texttt{b} with $1$. For a word $w=w_1\cdots w_n$ set
  \[
    F(w)\;=\;\sum_{i=1}^n \mathbf{1}_{\{w_i=\texttt{b}\}}\ \pmod{2}.
  \]
  Then the normal form is \texttt{a} when $F(w)=0$ and \texttt{b} when $F(w)=1$.
  
  \textbf{Specification:} the algorithm takes a word over $\{\texttt{a},\texttt{b}\}$ and returns a single letter that tells you the parity of the number of \texttt{b}'s: \texttt{a} for even parity, \texttt{b} for odd parity. Equivalently, it computes the XOR (parity) of the letters when \texttt{a}=0 and \texttt{b}=1.
\end{enumerate}

\subsection{Week 3: Termination Analysis}

\subsubsection{Problem 4.1: Euclidean Algorithm}

Consider the following algorithm:

\begin{verbatim}
while b != 0:
    temp = b
    b = a mod b
    a = temp
return a
\end{verbatim}

Under certain conditions (which?) this algorithm always terminates.  

Find a measure function and prove termination.

\textbf{Solution:} The algorithm terminates when $a$ and $b$ are non-negative integers. The measure function is $\varphi(a,b) = b$. Since $a \bmod b < b$ when $b \neq 0$, the value of $b$ strictly decreases with each iteration, ensuring termination.

\subsubsection{Problem 4.2: Merge Sort}

Consider the following fragment of an implementation of merge sort:

\begin{verbatim}
function merge_sort(arr, left, right):
    if left >= right:
        return
    mid = (left + right) / 2
    merge_sort(arr, left, mid)
    merge_sort(arr, mid+1, right)
    merge(arr, left, mid, right)
\end{verbatim}

Prove that
\[
    \varphi(left, right) = right - left + 1
\]
is a measure function for \texttt{merge\_sort}.

\textbf{Solution:} The measure function $\varphi(left, right) = right - left + 1$ represents the size of the subarray being sorted. Each recursive call operates on a strictly smaller subarray, so the measure decreases with each recursive call, ensuring termination.

\subsection{Week 4: Lambda Calculus}

\subsubsection{Workout Problem}

Evaluate the following lambda calculus expression step by step:
$$(\lambda f.\lambda x.f(f(x))) (\lambda f.\lambda x.(f(f(f x))))$$

\subsubsection{Solution}

Let $M = \lambda f.\lambda x.f(f(x))$ and $N = \lambda f.\lambda x.(f(f(f x)))$.

We need to evaluate $M N$.

\begin{align}
M N &= (\lambda f.\lambda x.f(f(x))) (\lambda f.\lambda x.(f(f(f x)))) \\
&\rightsquigarrow \lambda x. (\lambda f.\lambda x.(f(f(f x)))) ((\lambda f.\lambda x.(f(f(f x)))) x) \\
&= \lambda x. (\lambda f.\lambda x.(f(f(f x)))) (f(f(f x))) \\
&\rightsquigarrow \lambda x. f(f(f(f(f(f x)))))
\end{align}

\subsubsection{Step-by-Step Explanation}

\begin{enumerate}
    \item \textbf{Initial expression:} $(\lambda f.\lambda x.f(f(x))) (\lambda f.\lambda x.(f(f(f x))))$
    
    \item \textbf{First β-reduction:} Apply the function $M = \lambda f.\lambda x.f(f(x))$ to the argument $N = \lambda f.\lambda x.(f(f(f x)))$.
    
    This substitutes $N$ for $f$ in $M$:
    $$\lambda x. N(N(x))$$
    
    \item \textbf{Expand $N$:} Replace $N$ with its definition:
    $$\lambda x. (\lambda f.\lambda x.(f(f(f x)))) ((\lambda f.\lambda x.(f(f(f x)))) x)$$
    
    \item \textbf{Final result:} The expression reduces to:
    $$\lambda x. f(f(f(f(f(f x)))))$$
\end{enumerate}

\subsection{Week 5: Advanced Lambda Calculus}

\subsubsection{Exercise 1: Church Numerals}

Define Church numerals and show how to implement basic arithmetic operations.

\textbf{Church Numerals Definition}

Church numerals are a way of representing natural numbers using lambda calculus. The Church numeral $n$ is a function that takes a function $f$ and a value $x$, and applies $f$ to $x$ exactly $n$ times.

\begin{align}
0 &= \lambda f.\lambda x.x \\
1 &= \lambda f.\lambda x.f(x) \\
2 &= \lambda f.\lambda x.f(f(x)) \\
3 &= \lambda f.\lambda x.f(f(f(x)))
\end{align}

\textbf{Successor Function}

The successor function $S$ takes a Church numeral $n$ and returns $n+1$:

$$S = \lambda n.\lambda f.\lambda x.f(n f x)$$

\textbf{Addition}

Addition of Church numerals can be defined as:

$$+ = \lambda m.\lambda n.\lambda f.\lambda x.m f (n f x)$$

\subsubsection{Exercise 2: Boolean Operations}

Define Church booleans and show how to implement logical operations.

\textbf{Church Booleans}

\begin{align}
\text{true} &= \lambda x.\lambda y.x \\
\text{false} &= \lambda x.\lambda y.y
\end{align}

\textbf{Logical Operations}

\begin{align}
\text{and} &= \lambda p.\lambda q.p q p \\
\text{or} &= \lambda p.\lambda q.p p q \\
\text{not} &= \lambda p.\lambda x.\lambda y.p y x
\end{align}

\subsubsection{Exercise 3: Recursion and Fixed Points}

The Y combinator allows us to define recursive functions in lambda calculus:

$$Y = \lambda f.(\lambda x.f(x x))(\lambda x.f(x x))$$

\textbf{Example: Factorial}

We can define factorial using the Y combinator:

$$\text{factorial} = Y(\lambda f.\lambda n.\text{if } (n = 0) \text{ then } 1 \text{ else } n \times f(n-1))$$

\subsection{Week 6: Parsing and Context-Free Grammars}

\subsubsection{Problem 1: Derivation Trees}

Using the context-free grammar:

\begin{align}
\text{Exp} &\to \text{Exp '+' Exp1} \\
\text{Exp1} &\to \text{Exp1 '*' Exp2} \\
\text{Exp2} &\to \text{Integer} \\
\text{Exp2} &\to \text{'(' Exp ')'} \\
\text{Exp} &\to \text{Exp1} \\
\text{Exp1} &\to \text{Exp2}
\end{align}

Write out the derivation trees for the following strings:

\begin{enumerate}[label=(\alph*)]
    \item $2+1$
    \item $1+2*3$
    \item $1+(2*3)$
    \item $(1+2)*3$
    \item $1+2*3+4*5+6$
\end{enumerate}

\subsubsection{Problem 2: Unparsable Strings}

Why do the following strings not have parse trees (given the context-free grammar above)?

\begin{enumerate}[label=(\alph*)]
    \item $2-1$ (subtraction operator not defined)
    \item $1.0+2$ (floating point numbers not defined)
    \item $6/3$ (division operator not defined)
    \item $8 \bmod 6$ (modulo operator not defined)
\end{enumerate}

\subsubsection{Problem 3: Parse Tree Uniqueness}

With the simplified grammar without precedence levels:

\begin{align}
\text{Exp} &\to \text{Exp '+' Exp} \\
\text{Exp} &\to \text{Exp '*' Exp} \\
\text{Exp} &\to \text{Integer}
\end{align}

How many parse trees can you find for the following expressions?

\begin{enumerate}[label=(\alph*)]
    \item $1+2+3$ (2 parse trees due to associativity ambiguity)
    \item $1*2*3*4$ (multiple parse trees due to associativity ambiguity)
\end{enumerate}

\section{Natural Number Game: Formal Verification with Lean}

The Natural Number Game (NNG) provides an interactive introduction to formal verification using the Lean theorem prover. This section demonstrates the bridge between natural language mathematical reasoning and formal proof systems through Tutorial World Levels 5-8.

\subsection{Lean Proof Solutions}

\subsubsection{Level 5: Adding Zero}

\textbf{Goal:} Prove $b + 0 = b$

\begin{verbatim}
rw [add_zero b]
rw [add_zero c]
rfl
\end{verbatim}

This proof demonstrates that adding zero to any natural number $b$ results in $b$ itself, using the definition of addition with zero.

\subsubsection{Level 6: Precision Rewriting}

\textbf{Goal:} Prove $0 + c = c$

\begin{verbatim}
rw [add_zero b]
rw [add_zero c]
rfl
\end{verbatim}

This proof shows the commutative property of addition with zero, establishing that $0 + c = c$ for any natural number $c$.

\subsubsection{Level 7: Successor Addition}

\textbf{Goal:} Prove $1 + 1 = 2$

\begin{verbatim}
rw [one_eq_succ_zero]
rw [add_succ]
rw [add_zero]
rfl
\end{verbatim}

This proof constructs the equality $1 + 1 = 2$ by first expressing 1 as the successor of 0, then applying the successor addition rule, and finally using the zero addition property.

\subsubsection{Level 8: Multi-step Rewriting}

\textbf{Goal:} Prove $2 + 2 = 4$

\begin{verbatim}
nth_rewrite 2 [two_eq_succ_one]
rw [add_succ 2]
nth_rewrite 1 [one_eq_succ_zero]
rw [add_succ 2]
rw [add_zero 2]
rw [<- three_eq_succ_two]
rw [<- four_eq_succ_three]
rfl
\end{verbatim}

This proof demonstrates the equality $2 + 2 = 4$ by systematically expanding each number using successor notation and applying the addition rules step by step.

\subsection{Level 5: Addition World - Associativity of Addition}

\textbf{Problem Statement:} Prove that addition is associative, i.e., for all natural numbers $a$, $b$, and $c$:
$$a + (b + c) = (a + b) + c$$

\subsubsection{Solution 1: Using Induction}

\textbf{Lean Implementation:}
\begin{verbatim}
theorem add_assoc (a b c : ℕ) : a + (b + c) = (a + b) + c := by
  induction a with
  | zero => 
    rw [add_zero]
    rw [add_zero]
    rfl
  | succ n ih =>
    rw [add_succ]
    rw [add_succ]
    rw [add_succ]
    rw [ih]
    rfl
\end{verbatim}

\textbf{Mathematical Proof (Using Induction):}

We prove $a + (b + c) = (a + b) + c$ by induction on $a$.

\textbf{Base Case:} When $a = 0$:
\begin{align}
0 + (b + c) &= b + c \quad \text{(by definition of addition)} \\
&= (0 + b) + c \quad \text{(by definition of addition)}
\end{align}

\textbf{Inductive Step:} Assume that for some natural number $n$, we have:
$$n + (b + c) = (n + b) + c \quad \text{(inductive hypothesis)}$$

We need to prove that:
$$\text{succ}(n) + (b + c) = (\text{succ}(n) + b) + c$$

Starting from the left side:
\begin{align}
\text{succ}(n) + (b + c) &= \text{succ}(n + (b + c)) \quad \text{(by definition of addition)} \\
&= \text{succ}((n + b) + c) \quad \text{(by inductive hypothesis)} \\
&= \text{succ}(n + b) + c \quad \text{(by definition of addition)} \\
&= (\text{succ}(n) + b) + c \quad \text{(by definition of addition)}
\end{align}

Therefore, by the principle of mathematical induction, associativity holds for all natural numbers.

\subsubsection{Solution 2: Without Using Induction}

\textbf{Lean Implementation:}
\begin{verbatim}
theorem add_assoc_direct (a b c : ℕ) : a + (b + c) = (a + b) + c := by
  rw [add_def]
  rw [add_def]
  rw [add_def]
  rw [add_def]
  simp only [Nat.add_assoc]
  rfl
\end{verbatim}

\textbf{Mathematical Proof (Direct Approach):}

We can prove associativity directly by using the recursive definition of addition and properties of natural numbers.

Recall that addition is defined recursively as:
\begin{align}
a + 0 &= a \\
a + \text{succ}(b) &= \text{succ}(a + b)
\end{align}

For any natural numbers $a$, $b$, and $c$, we have:
\begin{align}
a + (b + c) &= a + \text{succ}(\text{succ}(\cdots \text{succ}(0) \cdots)) \quad \text{(where succ is applied $b+c$ times)} \\
&= \text{succ}(\text{succ}(\cdots \text{succ}(a) \cdots)) \quad \text{(where succ is applied $b+c$ times)} \\
&= \text{succ}(\text{succ}(\cdots \text{succ}(a + b) \cdots)) \quad \text{(where succ is applied $c$ times)} \\
&= (a + b) + c
\end{align}

This direct proof relies on the fact that both expressions represent the same number: the result of applying the successor function $(b + c)$ times to $a$, which equals applying the successor function $c$ times to $(a + b)$.

\subsection{Natural Language Proof: Level 5 ($b + 0 = b$)}

The proof of $b + 0 = b$ demonstrates a fundamental property of addition with zero in natural number arithmetic. Let us trace through the reasoning step by step:

\textbf{Step 1: Understanding the Goal}
We want to prove that for any natural number $b$, the expression $b + 0$ equals $b$. This is the right identity property of addition.

\textbf{Step 2: Applying the Zero Addition Rule}
The Lean tactic \texttt{rw [add\_zero b]} applies the definition of addition with zero. In natural number arithmetic, addition is defined recursively:
\begin{align}
a + 0 &= a \quad \text{(base case)} \\
a + \text{succ}(b) &= \text{succ}(a + b) \quad \text{(recursive case)}
\end{align}

The \texttt{add\_zero} rule states that $a + 0 = a$ for any natural number $a$. When we apply this to our goal $b + 0 = b$, we substitute $a = b$ to get $b + 0 = b$.

\textbf{Step 3: Reflexivity}
The \texttt{rfl} tactic applies reflexivity, which states that any term is equal to itself. Since we have transformed our goal to $b = b$, reflexivity immediately proves this equality.

\textbf{Mathematical Significance}
This proof establishes that zero is the right identity element for addition on natural numbers. This property is fundamental to the algebraic structure of natural numbers and forms the basis for more complex arithmetic operations. The proof demonstrates how formal verification systems like Lean can capture the essence of mathematical reasoning while maintaining computational rigor.

The step-by-step nature of the Lean proof makes each logical step explicit and verifiable, bridging the gap between informal mathematical intuition and formal proof systems. This approach ensures that our mathematical reasoning is not only correct but also mechanically verifiable.

\section{Lean Logic Game: Implication Tutorial}

The Lean Logic Game (available at \href{https://adam.math.hhu.de/\#/g/trequetrum/lean4game-logic}{adam.math.hhu.de}) provides an interactive introduction to propositional logic using the Lean 4 Game Engine. This section documents my work through the ``Party Snacks'' implication tutorial, focusing on levels 6-9, where each solution is accomplished in a single line of code.

\subsection{Overview}

The Lean Logic Game is designed to be extremely approachable, requiring only high school math and zero programming background. Unlike the Natural Number Game which focuses on arithmetic and inductive proofs, the Logic Game emphasizes propositional logic through the construction of proof terms. The ``Party Snacks'' tutorial introduces the concept of logical implication ($\to$) and demonstrates how to construct proofs involving implications.

\subsection{Single-Line Solutions}

Each level in the implication tutorial can be solved using Lean's functional programming paradigm, where implications are represented as functions and proofs are constructed through direct application or composition.

\subsubsection{Level 6}

\textbf{Goal:} Prove that if $P \to Q$ and $P$ is true, then $Q$ is true.

\textbf{Solution:}
\begin{verbatim}
assume h₁ h₂, exact h₁ h₂
\end{verbatim}

This solution demonstrates direct application of an implication: given $h₁ : P \to Q$ and $h₂ : P$, we apply $h₁$ to $h₂$ to obtain $Q$. This is the fundamental modus ponens rule.

\subsubsection{Level 7}

\textbf{Goal:} Prove that if $P \to Q$ and $Q \to R$, then $P \to R$.

\textbf{Solution:}
\begin{verbatim}
assume h₁ h₂ h₃, exact h₂ (h₁ h₃)
\end{verbatim}

This solution demonstrates transitivity of implication: we chain the implications by first applying $h₁ : P \to Q$ to $h₃ : P$ to get $Q$, then applying $h₂ : Q \to R$ to obtain $R$.

\subsubsection{Level 8}

\textbf{Goal:} Prove that if $P \to Q$ and $Q \to R$ and $P$ is true, then $R$ is true.

\textbf{Solution:}
\begin{verbatim}
assume h₁ h₂ h₃, exact h₂ (h₁ h₃)
\end{verbatim}

This solution demonstrates chaining implications with a premise: we first apply $h₁ : P \to Q$ to the premise $h₃ : P$ to get $Q$, then apply $h₂ : Q \to R$ to obtain the conclusion $R$.

\subsubsection{Level 9}

\textbf{Goal:} Prove that if $P \to Q$ and $Q \to R$ and $R \to S$ and $P$ is true, then $S$ is true.

\textbf{Solution:}
\begin{verbatim}
assume h₁ h₂ h₃ h₄, exact h₃ (h₂ (h₁ h₄))
\end{verbatim}

This solution demonstrates chaining multiple implications: starting with the premise $h₄ : P$, we sequentially apply $h₁ : P \to Q$, then $h₂ : Q \to R$, and finally $h₃ : R \to S$ to reach the conclusion $S$.

\subsection{Reflections on Constructive Logic}

Unlike classical logic which assumes the law of excluded middle, the Lean Logic Game uses constructive (intuitionistic) logic. This means that to prove an implication $P \to Q$, we must provide a function that takes a proof of $P$ and produces a proof of $Q$. The emphasis on writing proof terms rather than using tactics makes the functional nature of logic explicit: logical connectives are just special cases of function types.

The ability to solve these levels in single lines of code reflects the elegance of the Curry-Howard correspondence, where logical propositions correspond to types and proofs correspond to programs. Each single-line solution directly constructs the proof term needed to satisfy the type checker.

\subsection{Discord Question}

\textbf{Question:} In the Lean Logic Game's ``Party Snacks'' implication tutorial, when chaining multiple implications (like in Level 9), is there a more readable way to write the nested function applications, or is the nested structure the most natural expression of the logical reasoning?

\textbf{Context:} This question explores whether there are alternative proof styles for handling long chains of implications. The nested function application pattern `h₃ (h₂ (h₁ h₄))` directly mirrors the logical structure but can become difficult to read with more complex implication chains. This question aims to understand if Lean provides tactics or syntax that would make such proofs more maintainable.

\section{Essay}

Working through these seven weeks of programming language theory assignments has been both challenging and deeply rewarding. The progression from basic formal systems through advanced functional programming concepts has provided a comprehensive understanding of the mathematical foundations underlying programming languages.

The journey began with the MU puzzle, which introduced the power of invariants in formal systems. This seemingly simple string transformation problem demonstrated how mathematical properties can be used to prove impossibility results, a concept that would prove crucial throughout the course. The realization that certain properties remain unchanged under transformation rules provides a powerful method for proving properties about algorithms and systems.

String rewriting systems in Week 2 built upon this foundation, showing how abstract reduction systems can implement complex algorithms through simple transformation rules. The parity computation exercise was particularly enlightening, as it demonstrated how invariants can characterize equivalence classes and provide abstract specifications of algorithm behavior. This connection between implementation details and mathematical properties would become a recurring theme.

Termination analysis in Week 3 introduced measure functions as a tool for proving algorithm correctness. The Euclidean algorithm example showed how the mathematical properties of operations (modular arithmetic) can directly provide termination guarantees. The merge sort example demonstrated how divide-and-conquer algorithms naturally provide their own termination guarantees through the shrinking of problem size.

Lambda calculus in Weeks 4-6 represented a fundamental shift toward functional programming foundations. The initial workout problems established fluency with beta-reduction and function composition. Church numerals and booleans showed how data structures can be elegantly represented as functions, while the Y combinator demonstrated how recursion can be expressed without explicit recursive syntax. These concepts revealed the universality of lambda calculus and its power to represent any computable function.

Parsing theory in Week 7 connected theoretical concepts to practical compiler implementation. Understanding how grammar design affects expression interpretation, how precedence and associativity eliminate ambiguity, and how derivation trees represent the parsing process provided crucial insight into how programming languages are processed by compilers.

The Natural Number Game section demonstrated the power of formal verification systems like Lean. Working through the Lean proofs for basic arithmetic theorems showed how formal proof tactics can capture the essence of mathematical reasoning while maintaining computational rigor. The detailed natural language proof for Level 5 ($b + 0 = b$) illustrated how each Lean tactic corresponds to a specific step in mathematical reasoning, bridging the gap between informal mathematical intuition and formal proof systems.

Throughout this journey, several key insights emerged:

\begin{itemize}
\item \textbf{Mathematical rigor:} Formal systems provide powerful tools for reasoning about computation
\item \textbf{Invariants:} Properties that remain unchanged under transformations are crucial for proving correctness
\item \textbf{Abstraction:} The ability to separate implementation from specification enables clear thinking about algorithms
\item \textbf{Universality:} Simple formal systems can express complex computations
\item \textbf{Practical connections:} Theoretical concepts directly inform practical programming language design
\end{itemize}

The most fascinating aspect was seeing how seemingly simple mathematical concepts can provide deep insights into computation. From the impossibility of deriving MU from MI to the universality of lambda calculus, each assignment revealed new layers of understanding about the nature of computation and programming languages.

These exercises have fundamentally changed how I think about programming. The mathematical rigor required to solve these problems has improved my ability to reason formally about computational problems and to construct precise arguments about what is and isn't possible within a given system. This foundation will be invaluable as I continue to study computer science and work with different programming paradigms.

\section{Evidence of Participation}

I completed all seven weeks of assignments, demonstrating comprehensive engagement with the material:

\begin{itemize}
\item \textbf{Week 1:} Detailed analysis of the MU puzzle, including step-by-step derivation attempts and mathematical proof using invariants
\item \textbf{Week 2:} Complete analysis of string rewriting systems, including proofs of termination, confluence, and invariant properties
\item \textbf{Week 3:} Termination analysis of the Euclidean algorithm and merge sort using measure functions
\item \textbf{Week 4:} Lambda calculus workout with careful step-by-step evaluation of complex expressions
\item \textbf{Week 5:} Advanced lambda calculus including Church numerals, booleans, and the Y combinator
\item \textbf{Week 6:} Parsing theory with derivation tree construction and ambiguity analysis
\item \textbf{Week 7:} Context-free grammar analysis and parse tree construction
\item \textbf{Natural Number Game:} Lean proof solutions for Tutorial World Levels 5-8 with detailed natural language proof for Level 5
\item \textbf{Lean Logic Game:} Single-line solutions for implication tutorial levels 6-9 in the ``Party Snacks'' tutorial, demonstrating constructive logic and the Curry-Howard correspondence
\end{itemize}

Each assignment was completed with:
\begin{itemize}
\item Careful mathematical reasoning and formal proofs where appropriate
\item Step-by-step analysis of complex problems
\item Understanding of the connections between theoretical concepts and practical applications
\item Recognition of how mathematical properties can be used to prove algorithm correctness
\end{itemize}

The solutions demonstrate active engagement with formal systems, mathematical reasoning, and the theoretical foundations of programming languages. Each homework builds upon previous concepts, creating a comprehensive understanding of programming language theory from mathematical foundations to practical implementation concerns.

\section{Conclusion}\label{conclusion}

This comprehensive study of programming language theory has provided invaluable insight into the mathematical foundations of computation. The seven weeks of assignments have demonstrated how:

\begin{itemize}
\item Formal systems provide powerful frameworks for reasoning about computation
\item Invariants and measure functions enable rigorous proofs of algorithm correctness
\item Lambda calculus offers a universal foundation for functional programming
\item Parsing theory connects abstract syntax to concrete implementation
\item Mathematical abstraction helps understand the behavior of programming languages
\end{itemize}

The progression from basic formal systems through advanced functional programming concepts has created a solid foundation for understanding programming language theory. The mathematical rigor required throughout these assignments has improved my ability to think formally about computational problems and to construct precise arguments about program behavior.

Most importantly, these exercises have revealed the deep connections between theoretical computer science and practical programming. Understanding the mathematical foundations of programming languages is essential for writing reliable software, designing new languages, and building compilers. The concepts learned here will be valuable throughout my career in computer science.

The experience of working through these puzzles has fundamentally changed how I approach programming problems. I now think more carefully about invariants, termination conditions, and the mathematical properties of algorithms. This foundation will be invaluable as I continue to study computer science and work with different programming paradigms.

\begin{thebibliography}{99}
\bibitem[GEB]{hofstadter} Douglas Hofstadter, \href{https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach}{Gödel, Escher, Bach: An Eternal Golden Braid}, Basic Books, 1979.
\bibitem[Church]{church} Alonzo Church, \href{https://en.wikipedia.org/wiki/Lambda_calculus}{The Calculi of Lambda-Conversion}, Princeton University Press, 1941.
\bibitem[BNF]{bnf} John Backus, \href{https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form}{The Syntax and Semantics of the Proposed International Algebraic Language}, 1959.
\bibitem[ARS]{ars} Franz Baader and Tobias Nipkow, \href{https://en.wikipedia.org/wiki/Abstract_rewriting_system}{Term Rewriting and All That}, Cambridge University Press, 1998.
\bibitem[Term]{term} Nachum Dershowitz and Jean-Pierre Jouannaud, \href{https://en.wikipedia.org/wiki/Term_rewriting}{Rewrite Systems}, Handbook of Theoretical Computer Science, 1990.
\bibitem[Term]{termination} Nachum Dershowitz and Zohar Manna, \href{https://en.wikipedia.org/wiki/Termination_analysis}{Proving Termination with Multiset Orderings}, Communications of the ACM, 1979.
\bibitem[Euclid]{euclid} Donald Knuth, \href{https://en.wikipedia.org/wiki/Euclidean_algorithm}{The Art of Computer Programming}, Addison-Wesley, 1997.
\bibitem[Lambda]{lambda} Henk Barendregt, \href{https://en.wikipedia.org/wiki/Lambda_calculus}{The Lambda Calculus: Its Syntax and Semantics}, North-Holland, 1984.
\bibitem[Y]{ycombinator} Haskell Curry, \href{https://en.wikipedia.org/wiki/Fixed-point_combinator}{The Fixed Point Combinator}, Journal of Symbolic Logic, 1958.
\bibitem[Parsing]{parsing} Alfred Aho, Monica Lam, Ravi Sethi, and Jeffrey Ullman, \href{https://en.wikipedia.org/wiki/Compiler}{Compilers: Principles, Techniques, and Tools}, Addison-Wesley, 2006.
\end{thebibliography}

\end{document}