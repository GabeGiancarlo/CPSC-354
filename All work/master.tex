\documentclass[12pt]{article}

% Packages
\usepackage{amsmath, amssymb, amsthm}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{lipsum}
\usepackage{mathtools}
\usepackage{microtype}

% Page setup
\geometry{margin=1in}

% Title info
\title{String Rewriting Exercises (2025)}
\author{Gabriel Giancarlo}
\date{\today}

\begin{document}

\maketitle

\section*{Introduction}

\textit{Term Rewriting} refers to rewriting abstract syntax trees (typically without binders). 
\textit{String Rewriting} is the special case where we only rewrite strings (as opposed to trees). 
Normal forms, confluence, termination, invariants can all be studied in this simpler setting. 
Everything we will learn will also transfer to the generalisations of string rewriting. 
(And, btw, string rewriting is already Turing complete (Why?).)

\bigskip

In all of the following exercises the task is to analyse a so-called \textit{abstract reduction system} (ARS). 
An ARS $(A,\to)$ consists of a set $A$ of words (finite lists, strings) and $\to$ is a relation on $A$. 
When we specify a rewrite rule
\[
w \to v
\]
we understand that it can be applied inside any longer word. 
For example, the rewrite rule
\[
ba \to ab
\]
can be applied to rewrite the word $cbad$ to $cabd$.

\bigskip

\noindent\textbf{Footnote.} 
The math behind the exercises requires the material on equivalence relations, abstract reduction systems, termination and invariants, but it may be good to first try the exercises and then learn the math.

\bigskip

The exercises in this section come in form of puzzles. 
Think of each ARS as the \textbf{implementation of an algorithm}. 
The puzzle for you is to find out the \textbf{input-output behaviour} of the algorithm, that is, you have to find out what the algorithm is meant to compute. 
In each case, the task is to explain without mentioning the rules what specification the algorithm/ARS implements.

\medskip

\textbf{Definition.} 
An \textbf{abstract characterization} or a \textbf{specification} of an ARS is a description of its input/output behaviour that does not refer to the rules of the ARS (the implementation). 

\section*{The Task}

Roughly speaking, the task is as follows:

\begin{itemize}
    \item Show that the ARS is an algorithm (that is, the ARS is terminating and every input computes to a unique result $=$ the ARS has unique normal forms).
    \item Find the specification the ARS implements. This usually requires describing the equality (equivalence relation) generated by the rewrite relation independently of the rewrite relation itself by an invariant.
\end{itemize}

\section*{The Roadmap}

\textit{(Skip this at first reading.)}

Here is a roadmap that you may find useful:

\begin{itemize}
    \item The basic question is how many equivalence classes there are and how we can recognise in which equivalence class a given word is.
    \item Collect basic facts and observations. Are there normal forms? What are they? Do all elements reduce to a normal form? Are normal forms unique?
    \item Does the system terminate?
    \item Can we characterise equivalence classes by unique normal forms?
    \item Can we characterise equivalence classes by invariants?
    \item Derive a specification from the invariant.
\end{itemize}

\section*{Exercises (The Method)}

The purpose of these exercises is not so much to practice problem solving but rather to learn the method of decidability via rewriting to normal form and the method of invariants. 
In particular, the relationship between $\longrightarrow$ and $\stackrel{\ast}{\longleftrightarrow}$ is important here.

\section*{Exercise 1}

The rewrite rule is:

\[
    ba \to ab
\]

\subsection*{Why does the ARS terminate?}
The system always terminates because every time we apply the rule, the letters get closer to being in the correct order. There are only a limited number of ways to reorder a finite string, so eventually no more rules can be applied.

\subsection*{What is the result of a computation (the normal form)?}
The normal form is the string where all the \texttt{a}'s come before all the \texttt{b}'s. For example, starting with \texttt{baba} we eventually reach \texttt{aabb}.

\subsection*{Show that the result is unique (the ARS is confluent).}
Yes, the result is unique. No matter how we choose to apply the rule, we always end up with the same final string: all the \texttt{a}'s on the left and all the \texttt{b}'s on the right. This shows the system is confluent.

\subsection*{What specification does this algorithm implement?}
This algorithm basically sorts the string by moving all the \texttt{a}'s to the left and the \texttt{b}'s to the right. In other words, it implements a simple sorting process.

\subsection*{Exercise 2}

The rewrite rules are:
\[
\texttt{aa} \to \texttt{a},\qquad
\texttt{bb} \to \texttt{a},\qquad
\texttt{ab} \to \texttt{b},\qquad
\texttt{ba} \to \texttt{b}.
\]

\begin{enumerate}[label=(\alph*)]
  \item \textbf{Why does the ARS terminate?}
  
  Every rule replaces two adjacent letters by a single letter, so each rewrite step strictly decreases the length of the word by exactly $1$. Since words are finite, you can't keep shortening forever. Therefore every rewrite sequence must stop after finitely many steps, so the ARS terminates.
  
  \item \textbf{What are the normal forms?}
  
  Because each step reduces length by $1$, any normal form must be a word that cannot be shortened further. The only words of length $1$ are \texttt{a} and \texttt{b}, and they contain no length-$2$ substring to rewrite, so they are normal. There are no other normal forms (every word of length $\ge 2$ has some adjacent pair and so admits a rewrite), hence the normal forms are exactly
  \[
    \texttt{a}\quad\text{and}\quad\texttt{b}.
  \]
  
  \item \textbf{Is there a string \(s\) that reduces to both \texttt{a} and \texttt{b}?}
  
  No. Intuitively, the rules preserve whether the number of \texttt{b}'s is even or odd (see part (d)), and \texttt{a} has zero \texttt{b}'s (even) while \texttt{b} has one \texttt{b} (odd). So a given input cannot end up as both \texttt{a} and \texttt{b}. Concretely: since the system terminates and every input has at least one normal form, and because an invariant (parity of \#\texttt{b}'s) distinguishes \texttt{a} from \texttt{b}, no string can reduce to both.
  
  \item \textbf{Show that the ARS is confluent.}
  
  We use the invariant ``number of \texttt{b}'s modulo $2$'' to argue confluence together with termination.
  
  \begin{itemize}
    \item Check the invariant: each rule changes the string locally but does not change the parity of the number of \texttt{b}'s.
      \begin{itemize}
        \item $\texttt{aa}\to\texttt{a}$: number of \texttt{b}'s unchanged (both sides have 0 \texttt{b}'s).
        \item $\texttt{bb}\to\texttt{a}$: two \texttt{b}'s are removed, so \#\texttt{b} decreases by $2$ (parity unchanged).
        \item $\texttt{ab}\to\texttt{b}$ and $\texttt{ba}\to\texttt{b}$: before there is exactly one \texttt{b}, after there is one \texttt{b} (parity unchanged).
      \end{itemize}
    \item By termination, every word rewrites in finitely many steps to some normal form (either \texttt{a} or \texttt{b}). Because parity of \#\texttt{b} is invariant, a word with even \#\texttt{b} cannot reach \texttt{b} (which has odd \#\texttt{b}) and a word with odd \#\texttt{b} cannot reach \texttt{a}. So each input has exactly one possible normal form determined by that parity.
  \end{itemize}
  
  Termination plus the fact that every input has a unique normal form implies confluence (there can't be two different normal forms reachable from the same input). So the ARS is confluent.
  
  \item \textbf{Which words become equal if we replace `$\to$' by `$=$`?}
  
  If we let `$=$` be the equivalence relation generated by the rewrite rules, then two words are equivalent exactly when they have the same parity of \texttt{b}'s. In other words:
  \[
    u = v \quad\Longleftrightarrow\quad |u|_{\texttt{b}} \equiv |v|_{\texttt{b}} \pmod{2}.
  \]
  So there are exactly two equivalence classes: the class of words with an even number of \texttt{b}'s (these are all equivalent to \texttt{a}) and the class of words with an odd number of \texttt{b}'s (these are all equivalent to \texttt{b}).
  
  \item \textbf{Characterise the equality abstractly / using modular arithmetic / final specification.}
  
  An abstract (implementation-free) description is: the system computes the parity of the number of \texttt{b}'s in the input word. If the number of \texttt{b}'s is even, the output is \texttt{a}; if it is odd, the output is \texttt{b}.
  
  A modular-arithmetic formulation: identify \texttt{a} with $0$ and \texttt{b} with $1$. For a word $w=w_1\cdots w_n$ set
  \[
    F(w)\;=\;\sum_{i=1}^n \mathbf{1}_{\{w_i=\texttt{b}\}}\ \pmod{2}.
  \]
  Then the normal form is \texttt{a} when $F(w)=0$ and \texttt{b} when $F(w)=1$.
  
  \textbf{Specification:} the algorithm takes a word over $\{\texttt{a},\texttt{b}\}$ and returns a single letter that tells you the parity of the number of \texttt{b}'s: \texttt{a} for even parity, \texttt{b} for odd parity. Equivalently, it computes the XOR (parity) of the letters when \texttt{a}=0 and \texttt{b}=1.
\end{enumerate}

\bigskip

\textbf{Example (work shown).} Start with \texttt{baba} (it has two \texttt{b}'s, so parity is even, we expect \texttt{a}):
\[
\texttt{baba} \xrightarrow{\ \texttt{ba}\to\texttt{b}\ } \texttt{bba}
\quad\xrightarrow{\ \texttt{bb}\to\texttt{a}\ } \texttt{aa}
\quad\xrightarrow{\ \texttt{aa}\to\texttt{a}\ } \texttt{a}.
\]
No matter which valid rewrites we choose at each step, we end up with \texttt{a}; that matches the parity-based specification above.

\subsection*{Exercise 3}

The rewrite rules are:
\[
\texttt{aa}\to\texttt{a},\qquad
\texttt{bb}\to\texttt{b},\qquad
\texttt{ba}\to\texttt{ab},\qquad
\texttt{ab}\to\texttt{ba}.
\]

\begin{enumerate}[label=(\alph*)]
  \item \textbf{Why does the ARS \emph{not} terminate?}
  
  It doesn't terminate because of the two swapping rules \(\texttt{ab}\to\texttt{ba}\) and \(\texttt{ba}\to\texttt{ab}\). These two rules can be applied back and forth forever on the substring \(\texttt{ab}\). For example
  \[
    \texttt{ab}\ \longrightarrow\ \texttt{ba}\ \longrightarrow\ \texttt{ab}\ \longrightarrow\ \cdots
  \]
  so there is an infinite rewrite sequence. The presence of such an endless swap means the system as a whole is not terminating (even though the shortening rules \(\texttt{aa}\to\texttt{a}\) and \(\texttt{bb}\to\texttt{b}\) would sometimes shorten words).
  
  \item \textbf{What are the normal forms?}
  
  A normal form is a word with no left-hand-side of any rule as a substring. Since the four left-hand sides are exactly the four possible length-2 pairs \(\{aa,bb,ab,ba\}\), every word of length \(\ge 2\) contains some reducible pair and so is not irreducible. Thus the only irreducible words (normal forms) are the words of length \(0\) or \(1\):
  \[
    \varepsilon,\ \texttt{a},\ \texttt{b}.
  \]
  (Here \(\varepsilon\) is the empty word.)
  
  Note: even though \(\varepsilon,a,b\) are the only irreducible words, not every input actually reaches one of them by rewriting, because you can get stuck in infinite swapping instead of ever applying the shortening rules.
  
  \item \textbf{Modify the ARS so it is terminating and has unique normal forms, while keeping the same equivalence relation.}
  
  A simple fix is to remove one of the swapping rules so swaps only go in one direction. For example, keep
  \[
    \texttt{aa}\to\texttt{a},\qquad
    \texttt{bb}\to\texttt{b},\qquad
    \texttt{ba}\to\texttt{ab},
  \]
  but \emph{drop} the rule \(\texttt{ab}\to\texttt{ba}\).
  
  Why this works:
  \begin{itemize}
    \item Every step either shortens the word (the \(\texttt{aa}\) or \(\texttt{bb}\) rules remove one letter) or strictly decreases the number of inversions (the \(\texttt{ba}\to\texttt{ab}\) step moves an \texttt{a} left of a \texttt{b}, decreasing the inversion count). Combining length and inversion gives a well-founded measure that strictly decreases with every rewrite step, so there can be no infinite rewrite sequences — the modified system is terminating.
    \item Because \(\texttt{ba}\to\texttt{ab}\) moves all \texttt{a}'s to the left of \texttt{b}'s and the \(\texttt{aa},\texttt{bb}\) rules collapse repeated letters, every word reduces to one of the four short canonical forms
    \[
      \varepsilon,\ \texttt{a},\ \texttt{b},\ \texttt{ab},
    \]
    and in fact the last two-letter form is always \(\texttt{ab}\) (not \(\texttt{ba}\)) because swaps are directed. After collapsing duplicates, each letter appears at most once, and all \texttt{a}'s end up left of all \texttt{b}'s, so the unique normal form is determined by whether the word contains an \texttt{a} and/or a \texttt{b}.
    \item The equivalence relation generated by the original rules (the smallest equivalence containing the original \(\to\)) already makes \(\texttt{ab}\) and \texttt{ba} equivalent, because \(\texttt{ba}\to\texttt{ab}\) is one of the original rules (and equivalence closure makes relations symmetric). Thus removing \(\texttt{ab}\to\texttt{ba}\) does not change the equivalence relation generated by the rules: the equivalence classes are still the same, but the modified oriented system gives a terminating, confluent presentation with one canonical representative per class.
  \end{itemize}
  
  \item \textbf{Describe the specification implemented by the ARS (student level).}
  
  The system is basically deciding which letters appear in the input at least once. In plain terms:
  \begin{itemize}
    \item If the input has no \texttt{a} and no \texttt{b} (the empty word), the output is \(\varepsilon\).
    \item If the input contains at least one \texttt{a} but no \texttt{b}, the output is \(\texttt{a}\).
    \item If it contains at least one \texttt{b} but no \texttt{a}, the output is \(\texttt{b}\).
    \item If it contains both letters, the output is \(\texttt{ab}\) (we pick \texttt{ab} as the canonical representative).
  \end{itemize}
  So the algorithm computes the \emph{set of letters present} in the word (represented as a short canonical string). Another way to say this: the ARS collapses each long word to a compact indicator of which of the two letters occur at least once.
\end{enumerate}

\bigskip

\textbf{Short example (illustration).} Start with \(\texttt{aabbaa}\). Under the modified rules:
\[
\texttt{aabbaa}\xrightarrow{\ \texttt{aa}\to\texttt{a}\ } \texttt{abbaa}
\xrightarrow{\ \texttt{bb}\to\texttt{b}\ } \texttt{abaa}
\xrightarrow{\ \texttt{ba}\to\texttt{ab}\ } \texttt{aaba}
\xrightarrow{\ \texttt{aa}\to\texttt{a}\ } \texttt{aba}
\xrightarrow{\ \texttt{ba}\to\texttt{ab}\ } \texttt{aab}
\xrightarrow{\ \texttt{aa}\to\texttt{a}\ } \texttt{ab},
\]
and \(\texttt{ab}\) is the unique normal form (meaning the input contains both letters).

\subsection*{Exercise 4}

The rewrite rules are
\[
\texttt{ab}\to\texttt{ba},\qquad
\texttt{ba}\to\texttt{ab}.
\]

\begin{enumerate}[label=(\alph*)]
  \item \textbf{Why does the ARS not terminate?}
  
  This system doesn't terminate because the two rules allow you to swap an \texttt{a} and a \texttt{b} back and forth forever. The simplest example is the word \texttt{ab}:
  \[
    \texttt{ab}\longrightarrow\texttt{ba}\longrightarrow\texttt{ab}\longrightarrow\cdots
  \]
  So there are infinite rewrite sequences, and therefore the ARS is not terminating.
  
  \item \textbf{What are the normal forms?}
  
  A normal form is a word that has no left-hand side of any rule as a substring. Here the left-hand sides are exactly \(\texttt{ab}\) and \(\texttt{ba}\), i.e.\ any adjacent pair of different letters is reducible. So the only words with no reducible pairs are the words where every adjacent pair is the same letter — in other words, the constant words
  \[
    \varepsilon,\ \texttt{a}^n,\ \texttt{b}^n \quad (n\ge 1).
  \]
  Concretely: the empty word and all words consisting entirely of \texttt{a}'s or entirely of \texttt{b}'s are the irreducible words. Every word that contains both letters has at least one \texttt{ab} or \texttt{ba} and so is not in normal form.
  
  Note however that most words containing both letters never reduce to one of these normal forms under the given rules, because the rules only swap letters and never remove them.
  
  \item \textbf{Is the ARS confluent?}
  
  Yes — in a simple sense. Because each rule is the inverse of the other, the one-step relation $\to$ is symmetric, and so its reflexive-transitive closure $\to^{*}$ is an equivalence relation (it is reflexive, symmetric and transitive). If from a word \(w\) you can reach \(x\) and you can also reach \(y\), then by symmetry and transitivity you can go from \(x\) to \(y\) (via \(w\)), so \(x\) and \(y\) have a common descendant (for instance \(y\) itself). That meets the usual definition of confluence: any two descendants of a common ancestor have a common descendant.  

  So the system is confluent, even though it is not terminating.
  
  \item \textbf{What does this ARS `mean' (what specification does it implement)?}
  
  The rules only swap neighboring \texttt{a} and \texttt{b} letters, so they never change how many \texttt{a}'s and how many \texttt{b}'s a word has. The natural invariant is the pair \((|w|_{\texttt{a}},|w|_{\texttt{b}})\) (the counts of \texttt{a} and \texttt{b}). The equivalence relation generated by the rules therefore groups together exactly those words that have the same number of \texttt{a}'s and the same number of \texttt{b}'s — i.e.\ the words that are anagrams of each other.  

 The system doesn't delete or create letters, it only permutes them, so two words are considered equivalent iff they contain the same multiset of letters (same counts of \texttt{a} and \texttt{b}).
  
  \item \textbf{How to make it terminating with the same equivalence relation?}
  
  A common trick is to orient the swap in one direction only, for example keep
  \[
    \texttt{ba}\to\texttt{ab}
  \]
  but drop \(\texttt{ab}\to\texttt{ba}\). With only \(\texttt{ba}\to\texttt{ab}\) the system becomes exactly like the bubble-sort style system from Exercise 1:
  \begin{itemize}
    \item It terminates because every application of \(\texttt{ba}\to\texttt{ab}\) reduces the number of inversions (a finite natural measure), so you can't keep doing steps forever.
    \item It has unique normal forms \(a^{\,|w|_a} b^{\,|w|_b}\) (all \texttt{a}'s left, all \texttt{b}'s right).
    \item The equivalence relation generated by the original (two-way) swap is the same as the one generated by this one-way swap once you take symmetric, transitive closure: both say “letters can be permuted”, i.e.\ words with the same letter counts are equivalent. So orienting the swap yields a terminating, confluent presentation whose normal forms are the sorted representatives of the same equivalence classes.
  \end{itemize}
  So the modification gives a terminating ARS with unique normal forms while preserving the abstract meaning (same equivalence classes).
  
  \item \textbf{Example (small illustration).} Starting from \texttt{baba} under the original two-way rules you can keep swapping:
  \[
    \texttt{baba}\longrightarrow\texttt{abba}\longrightarrow\texttt{a b b a}\longrightarrow\cdots
  \]
  (you can always find swaps, and you can go back and forth.) Under the modified one-way rule \(\texttt{ba}\to\texttt{ab}\) you would instead push the \texttt{a}'s left and eventually get
  \[
    \texttt{baba}\xrightarrow{\ \texttt{ba}\to\texttt{ab}\ } \texttt{abba}
    \xrightarrow{\ \texttt{ba}\to\texttt{ab}\ } \texttt{a b b a}\xrightarrow{\ \text{repeat}\ } \texttt{aabb},
  \]
  and then collapse (if collapsing rules are present) to the canonical sorted form \(a^{|w|_a}b^{|w|_b}\).
\end{enumerate}

\subsection*{Exercise 5}

The rewrite rules are
\[
\texttt{ab}\longrightarrow\texttt{ba},\qquad
\texttt{ba}\longrightarrow\texttt{ab},\qquad
\texttt{aa}\longrightarrow\varepsilon,\qquad
\texttt{b}\longrightarrow\varepsilon.
\]

I will answer each bullet carefully and give short, clear justifications.

\medskip

\textbf{(i) Some sample reductions.}

\begin{itemize}
  \item Start with \(\texttt{abba}\).
  \[
    \texttt{abba}\xrightarrow{\ \texttt{b}\to\varepsilon\ } \texttt{aba}
    \xrightarrow{\ \texttt{ba}\to\texttt{ab}\ } \texttt{aab}
    \xrightarrow{\ \texttt{aa}\to\varepsilon\ } \texttt{b}
    \xrightarrow{\ \texttt{b}\to\varepsilon\ }\varepsilon.
  \]
  So \(\texttt{abba}\to^{*}\varepsilon\).
  \item Start with \(\texttt{bababa}\).
  \[
    \texttt{bababa}\xrightarrow{\ \texttt{b}\to\varepsilon\ } \texttt{ababa}
    \xrightarrow{\ \texttt{b}\to\varepsilon\ } \texttt{aaba}
    \xrightarrow{\ \texttt{aa}\to\varepsilon\ } \texttt{ba}
    \xrightarrow{\ \texttt{b}\to\varepsilon\ } \texttt{a}.
  \]
  So \(\texttt{bababa}\to^{*}\texttt{a}\).
\end{itemize}

(These choices of rewrite steps are not unique; other valid choices lead to the same equivalence-class representatives — see the invariant-based description below.)

\bigskip

\textbf{(ii) Why is the ARS not terminating?}

Because of the two swap rules \(\texttt{ab}\to\texttt{ba}\) and \(\texttt{ba}\to\texttt{ab}\), you can cycle forever on any alternating adjacent pair. The shortest example is \(\texttt{ab}\):
\[
\texttt{ab}\longrightarrow\texttt{ba}\longrightarrow\texttt{ab}\longrightarrow\cdots
\]
This gives an infinite rewrite sequence, so the system is not terminating. (The erasing rules exist, but they don't prevent the existence of infinite swapping sequences when you choose only swaps.)

\bigskip

\textbf{(iii) Find two strings that are not equivalent. How many non-equivalent strings can you find?}

A simple pair of non-equivalent strings is
\[
\texttt{a}\quad\text{and}\quad\varepsilon.
\]
They are not equivalent because no rule can turn \(\texttt{a}\) into \(\varepsilon\): the only erasing rules are \(\texttt{aa}\to\varepsilon\) (needs two \texttt{a}'s) and \(\texttt{b}\to\varepsilon\) (erases \texttt{b}'s). In particular, the parity of the number of \texttt{a}'s (even vs odd) cannot be changed by any step, so a single \texttt{a} (odd number of \texttt{a}'s) cannot become \(\varepsilon\) (zero \texttt{a}'s, even).

How many non-equivalent strings can we find? If we ask for \emph{pairwise non-equivalent} representatives, the ARS only distinguishes two equivalence classes (see next part). So up to equivalence there are only two distinct outcomes: one represented by \(\varepsilon\) and one represented by \(\texttt{a}\). Of course there are infinitely many distinct strings as concrete syntactic objects, but they fall into just two equivalence classes.

\bigskip

\textbf{(iv) How many equivalence classes does \(\stackrel{*}{\longleftrightarrow}\) have? Describe them; what are the normal forms?}

\emph{Invariant.} Swaps \(\texttt{ab}\leftrightarrow\texttt{ba}\) never change the counts of \texttt{a}'s or \texttt{b}'s. The rules \(\texttt{aa}\to\varepsilon\) removes two \texttt{a}'s, and \(\texttt{b}\to\varepsilon\) removes one \texttt{b}. Therefore the \emph{parity} of the number of \texttt{a}'s,
\[
|w|_{\texttt{a}}\pmod{2},
\]
is preserved by every rule. (Each step either removes 0, 2, or an even number of \texttt{a}'s.) So parity of \texttt{a}'s is an invariant.

\emph{Completeness / reachability to representatives.} Using swaps we can reorder letters arbitrarily (because the two-way swaps generate all permutations of positions), so we can gather all \texttt{a}'s together. Then repeatedly apply \(\texttt{aa}\to\varepsilon\) to cancel \texttt{a}'s in pairs; use \(\texttt{b}\to\varepsilon\) to erase any \texttt{b}'s. After these reductions every string is reduced to either
\[
\varepsilon \quad\text{(if the original had an even number of \texttt{a}'s),}
\qquad\text{or}\qquad
\texttt{a} \quad\text{(if the original had an odd number of \texttt{a}'s).}
\]
So there are exactly two equivalence classes, determined by the parity of \(\#\texttt{a}\). The two normal forms (irreducible representatives) are \(\varepsilon\) and \(\texttt{a}\). (They are irreducible since none of the four left-hand sides occurs in them.)

Thus \(\stackrel{*}{\longleftrightarrow}\) partitions all strings into two classes:
\[
\{w\mid |w|_{\texttt{a}}\text{ is even}\}\quad\text{and}\quad\{w\mid |w|_{\texttt{a}}\text{ is odd}\},
\]
with canonical normal forms \(\varepsilon\) and \(\texttt{a}\) respectively.

\bigskip

\textbf{(v) Can you modify the ARS so that it becomes terminating without changing its equivalence classes?}

Yes. A standard trick is to orient the swapping in one direction only (so swaps become a ``sorting'' operation) while keeping the erasing rules. For instance, replace the two-way swaps by a single directed rule
\[
\texttt{ba}\longrightarrow\texttt{ab}
\]
(only move \texttt{a}'s left). Keep \(\texttt{aa}\to\varepsilon\) and \(\texttt{b}\to\varepsilon\). Call this the modified ARS.

Why this preserves equivalence classes: the reflexive–symmetric–transitive closure of the original two-way swaps is the same as the closure generated by the one-way swap once you allow symmetric closure (permutations). In other words, the original equivalence relation said “letters can be permuted arbitrarily” — orienting swaps only gives a terminating presentation (a canonical way to permute) but does not change the equivalence relation when you take the equivalence closure.

Why the modified system terminates: use the pair
\[
\big(\mathrm{inv}(w),\ |w|\big)
\]
ordered lexicographically, where
\[
\mathrm{inv}(w)=\#\{(i<j)\mid w_i=\texttt{b},\ w_j=\texttt{a}\}
\]
is the number of ``inversions'' (a \texttt{b} before an \texttt{a}). Check each rule:

\begin{itemize}
  \item \(\texttt{ba}\to\texttt{ab}\) strictly decreases \(\mathrm{inv}(w)\) by at least \(1\), length unchanged.
  \item \(\texttt{aa}\to\varepsilon\) strictly decreases \(|w|\) (by \(2\)), while \(\mathrm{inv}(w)\) stays the same (there are no \texttt{b}'s involved in that pair).
  \item \(\texttt{b}\to\varepsilon\) strictly decreases \(|w|\) (by \(1\)), \(\mathrm{inv}(w)\) may decrease but at worst stays the same.
\end{itemize}

So every rewrite step strictly decreases the lexicographically ordered pair \((\mathrm{inv},|w|)\), which is a well-founded order on finite strings. Thus there are no infinite rewrite sequences in the modified system, i.e.\ it terminates. Because the reachable normal forms under the modified system are still exactly \(\varepsilon\) and \(\texttt{a}\), the equivalence classes are unchanged.

\bigskip

\textbf{(vi) A couple of natural questions about strings (a specification) that this ARS answers.}

Think of the ARS as an algorithm that reduces a given input string to a canonical representative. Two natural questions (specifications) that are decided by this ARS are:

\begin{enumerate}
  \item \emph{Does the input string have an even number of \texttt{a}'s?}  
  The ARS reduces the input to \(\varepsilon\) iff the answer is “yes”.
  \item \emph{Does the input string have an odd number of \texttt{a}'s?}  
  The ARS reduces the input to \(\texttt{a}\) iff the answer is “yes”.
\end{enumerate}

These are good specifications because they are complete invariants: the parity of \(\#\texttt{a}\) completely characterizes the equivalence class of any string (independent of the rewrite rules).

\bigskip

\textbf{Remark / answer to Exse 5b (change \(\texttt{aa}\to\varepsilon\) into \(\texttt{aa}\to\texttt{a}\)).}

Replace the rule \(\texttt{aa}\to\varepsilon\) by \(\texttt{aa}\to\texttt{a}\) and keep the rest. Then:

\begin{itemize}
  \item Any positive number of \texttt{a}'s collapses to a single \texttt{a} (repeatedly use \(\texttt{aa}\to\texttt{a}\)). All \texttt{b}'s still erase by \(\texttt{b}\to\varepsilon\).
  \item The relevant invariant is no longer parity; instead the invariant that classifies strings is whether the string contains at least one \texttt{a} or not.
  \item Therefore the equivalence classes become:
    \[
      \{w\mid |w|_{\texttt{a}}=0\}\quad\text{(all these are equivalent to }\varepsilon\text{),}
      \qquad
      \{w\mid |w|_{\texttt{a}}\ge 1\}\quad\text{(all equivalent to }\texttt{a}\text{).}
    \]
  \item Orienting swaps as above (say \(\texttt{ba}\to\texttt{ab}\)) again gives a terminating presentation with the same classes; a suitable measure is the same lexicographic pair \((\mathrm{inv}(w),|w|)\) or simply \((\mathrm{inv}(w),\#\texttt{a}>0,\ |w|)\) where the boolean \(\#\texttt{a}>0\) is treated in the order before \(|w|\).
\end{itemize}

So Exse 5b is similar in spirit but the invariant that captures meaning changes from ``parity of \texttt{a}'' to ``presence of at least one \texttt{a}''.

\bigskip

\textbf{Final short summary .}
\begin{itemize}
  \item The original system is not terminating because swaps can cycle.
  \item There are exactly two equivalence classes: words with an even number of \texttt{a}'s (class represented by \(\varepsilon\)) and words with an odd number of \texttt{a}'s (class represented by \(\texttt{a}\)).
  \item A terminating presentation that preserves the same equivalence relation is obtained by orienting swaps (e.g.\ \(\texttt{ba}\to\texttt{ab}\)) and using the measure \((\mathrm{inv}(w),|w|)\) to prove termination.
  \item The ARS answers a clear question: ``Is the number of \texttt{a}'s even or odd?'' (or in Exse 5b: ``Does the string contain any \texttt{a}'s at all?'').
\end{itemize}

\subsection*{Exercise 6}

The rewrite rules are
\[
\texttt{ba}\;\to\;\texttt{bbaa},\qquad
\texttt{aa}\;\to\;\varepsilon,\qquad
\texttt{ba}\;\to\;\texttt{ab},\qquad
\texttt{ab}\;\to\;\texttt{ba}.
\]
(So we have an expansion rule \(\texttt{ba}\to\texttt{bbaa}\) plus the usual swap rules and the erasing rule \(\texttt{aa}\to\varepsilon\).)

\bigskip

Below I answer the questions in a clear, undergrad style, showing the necessary work.

\paragraph{Notation / bookkeeping.}  
For a word \(w\) write \(|w|_a\) and \(|w|_b\) for the number of \(a\)'s and \(b\)'s in \(w\). The swap rules (\(\texttt{ab}\leftrightarrow\texttt{ba}\)) do not change these counts. The expansion \(\texttt{ba}\to\texttt{bbaa}\) changes counts by
\[
(\Delta|a|,\Delta|b|)=(+1,+1),
\]
and the erasure \(\texttt{aa}\to\varepsilon\) changes counts by
\[
(\Delta|a|,\Delta|b|)=(-2,0).
\]
So any net effect on counts coming from a combination of these two kinds of moves is an integer linear combination of \((1,1)\) and \((-2,0)\).

\bigskip

\textbf{(1) Can one reduce \(\texttt{ab}\) to \(\texttt{aabb}\)?}

Yes.

One concrete reduction sequence (using swaps and the expansion once) is:

\[
\begin{aligned}
\texttt{ab}
&\xrightarrow{\ \texttt{ab}\to\texttt{ba}\ } \texttt{ba} 
\xrightarrow{\ \texttt{ba}\to\texttt{bbaa}\ } \texttt{bbaa}\\
\texttt{bbaa}
&\xrightarrow{\ \texttt{ba}\to\texttt{ab}\ \text{at pos }2\text{-}3\ } \texttt{baba}
\xrightarrow{\ \texttt{ba}\to\texttt{ab}\ \text{at pos }1\text{-}2\ } \texttt{abba}\\
\texttt{abba}
&\xrightarrow{\ \texttt{ba}\to\texttt{ab}\ \text{at pos }3\text{-}4\ } \texttt{abab}
\xrightarrow{\ \texttt{ba}\to\texttt{ab}\ \text{at pos }2\text{-}3\ } \texttt{aabb}.
\end{aligned}
\]

So \(\texttt{ab}\to^{*}\texttt{aabb}\). (Intuitively: expand \(\texttt{ba}\) to \(\texttt{bbaa}\), then use swaps to bubble the two \(a\)'s to the left.)

\bigskip

\textbf{(2) Can one reduce \(\texttt{ba}\) to \(\texttt{abbaababbab}\)?}

No. Use counts as an obstruction.

Compute counts of the target \(t=\) \(\texttt{abbaababbab}\):
\[
|t|_a=5,\qquad |t|_b=6.
\]
If we start from \(\texttt{ba}\) then every time we apply the expansion \(\texttt{ba}\to\texttt{bbaa}\) we increase both counts by \(1\), and every time we apply \(\texttt{aa}\to\varepsilon\) we decrease \(|\cdot|_a\) by \(2\). Swaps do not change counts. Hence any word reachable from \(\texttt{ba}\) must have the form
\[
\big(|\cdot|_a,|\cdot|_b\big)
=\big(1+k-2m,\;1+k\big)
\]
for some integers \(k\ge0\) (number of expansions used) and \(m\ge0\) (number of \(aa\) cancellations used). From the \(b\)-count we get \(1+k=6\Rightarrow k=5\). Then the \(a\)-count would be \(1+5-2m=6-2m\). To get \(5\) we need \(6-2m=5\), i.e.\ \(2m=1\), impossible. So \(\texttt{ba}\not\to^{*}\texttt{abbaababbab}\).

\bigskip

\textbf{(3) Can one reduce \(\texttt{ba}\) to \(\texttt{abbaababbaba}\)?}

Yes. Again look at counts. For \(u=\texttt{abbaababbaba}\) we have (check)
\[
|u|_a=6,\qquad |u|_b=6.
\]
From the general form \((1+k-2m,1+k)\) we want \((1+k-2m,1+k)=(6,6)\). The \(b\)-equation gives \(1+k=6\Rightarrow k=5\). Then the \(a\)-equation becomes \(1+5-2m=6\Rightarrow 6-2m=6\Rightarrow m=0\). So with \(k=5,m=0\) the counts match, and swaps can then permute letters to arrange them into the exact target word. Thus a reduction exists (one can perform five expansions at suitable occurrences of \(\texttt{ba}\), then use swaps to permute the resulting letters into the target order). So \(\texttt{ba}\to^{*}\texttt{abbaababbaba}\) is possible.

(If you want a fully explicit long step-by-step sequence I can write one out, but the count+permutation argument already proves existence.)

\bigskip

\textbf{(4) Which words are in the equivalence class of \(\varepsilon\) and which in the class of \(\texttt{a}\)?}

We now consider the equivalence relation generated by the rules (i.e.\ the reflexive–symmetric–transitive closure of \(\to\)). Two words are equivalent iff one can be transformed to the other using the rules in either direction.

From the linear-change description above: any net change in counts produced by a combination of the expansion and the erasure is an integer combination of the vectors
\[
v_1=(1,1)\quad(\text{from }\texttt{ba}\leftrightarrow\texttt{bbaa}),\qquad
v_2=(-2,0)\quad(\text{from }\texttt{aa}\leftrightarrow\varepsilon).
\]
So if \(w\) and \(w'\) are equivalent then
\[
(|w'|_a-|w|_a,\;|w'|_b-|w|_b)=\lambda(1,1)+\mu(-2,0)=(\lambda-2\mu,\lambda)
\]
for some integers \(\lambda,\mu\). Eliminating \(\lambda\) gives the congruence
\[
|w'|_a - |w'|_b \equiv |w|_a - |w|_b \pmod{2}.
\]
So the parity of \(|w|_a-|w|_b\) is invariant under the equivalence relation. Conversely, one can show this invariant is complete: two words with the same value of \(|w|_a-|w|_b\) mod \(2\) are equivalent (you can realize the required \(\lambda,\mu\) and then use swaps to permute letters into the right pattern). Thus there are exactly two equivalence classes, determined by the parity of \(|w|_a-|w|_b\).

In particular:
\begin{itemize}
  \item The equivalence class of \(\varepsilon\) is precisely the set of words \(w\) with
  \[
  |w|_a - |w|_b \equiv 0 \pmod{2}.
  \]
  A convenient canonical representative is \(\varepsilon\) itself (or any other word with the same parity, but \(\varepsilon\) is the shortest).
  \item The equivalence class of \(\texttt{a}\) is precisely the set of words \(w\) with
  \[
  |w|_a - |w|_b \equiv 1 \pmod{2}.
  \]
  A good canonical representative is \(\texttt{a}\).
\end{itemize}

So: there are two equivalence classes only, and natural normal-form representatives are \(\varepsilon\) and \(\texttt{a}\) (minimal-length representatives).

\bigskip

\textbf{(5) Some invariants (properties that never change under the rules).}

\begin{itemize}
  \item The parity of \( |w|_a-|w|_b \) (i.e.\ \( |w|_a-|w|_b \pmod{2}\)) is invariant.
  \item Equivalently, \(|w|_a+|w|_b\) has fixed parity (since \(|w|_a+|w|_b \equiv |w|_a-|w|_b \pmod{2}\) for alphabets of size \(2\)).
  \item Swaps alone preserve the multiset of letters; expansion and erasure change counts only in the \(\mathbb{Z}\)-span generated by \((1,1)\) and \((-2,0)\). So any linear combination of counts that vanishes on both generators is invariant. Concretely, any integer linear functional \(L(a,b)=\alpha a+\beta b\) with \(\alpha(1)+\beta(1)\) and \(\alpha(-2)+\beta(0)\) both even will give a congruence-type invariant; the simplest useful one is the parity invariant above.
\end{itemize}

\bigskip

\textbf{(6) Describe all equivalence classes (summary).}

All words fall into exactly two classes:
\[
\{w:\ |w|_a-|w|_b \equiv 0\pmod{2}\}\quad\text{(class of }\varepsilon\text{)}
\]
and
\[
\{w:\ |w|_a-|w|_b \equiv 1\pmod{2}\}\quad\text{(class of }\texttt{a}\text{)}.
\]
Each class is infinite as concrete strings, but up to the generated equivalence they collapse to the two canonical representatives \(\varepsilon\) and \(\texttt{a}\).

\bigskip

\textbf{(7) Make the ARS terminating without changing equivalence classes.}

A standard method is to orient the rules so that every step strictly decreases a well-founded measure, while keeping at least one direction of each original relation so that the symmetric closure of the modified relation still generates the same equivalence relation.

One convenient choice is:
\[
\text{(i)}\quad \texttt{ba}\longrightarrow\texttt{ab}\quad(\text{only move }a\text{'s left}),\\
\]
\[
\text{(ii)}\quad \texttt{bbaa}\longrightarrow\texttt{ba}\quad(\text{contract the expansion}),\\
\]
\[
\text{(iii)}\quad \texttt{aa}\longrightarrow\varepsilon.
\]

So we replaced the two-way swaps by the single directed swap \(\texttt{ba}\to\texttt{ab}\) and replaced the expansion \(\texttt{ba}\to\texttt{bbaa}\) by the contractive direction \( \texttt{bbaa}\to\texttt{ba}\). The equivalence relation generated by this modified (directed) system has the same symmetric closure as the original system (because every original rule is still represented up to symmetry in the modified relation), so the equivalence classes do not change.

\emph{Measure / termination proof.} Define
\[
\mathrm{inv}(w)=\#\{(i<j)\mid w_i=\texttt{b},\ w_j=\texttt{a}\}
\]
(the usual inversion count: number of \(b\)s before \(a\)s), and let \(|w|\) be the length. Order pairs lexicographically with \(\mathrm{inv}\) as primary and \(|w|\) as secondary:
\[
(w) \mapsto (\mathrm{inv}(w),|w|),
\]
and compare these pairs lexicographically.

Check each rule of the modified system:
\begin{itemize}
  \item \(\texttt{ba}\to\texttt{ab}\) decreases \(\mathrm{inv}\) by \(1\) and leaves \(|w|\) unchanged.
  \item \(\texttt{bbaa}\to\texttt{ba}\) decreases \(|w|\) by \(2\) (and cannot increase \(\mathrm{inv}\) enough to cancel the lexicographic decrease).
  \item \(\texttt{aa}\to\varepsilon\) decreases \(|w|\) by \(2\).
\end{itemize}
Hence every rewrite strictly decreases the lexicographic pair \((\mathrm{inv},|w|)\). Since this pair ranges over \(\mathbb{N}\times\mathbb{N}\) with the lexicographic order (a well-founded order), infinite descending chains are impossible. Therefore the modified system terminates.

Because (a) the symmetric closure of the modified system generates the same equivalence as the original system and (b) the modified system terminates, we now have a terminating rewriting presentation that gives canonical normal forms (which are \(\varepsilon\) or \(\texttt{a}\) depending on parity).

\bigskip

\textbf{Remark.} The crucial conceptual point is: the algebra of net changes to \((|w|_a,|w|_b)\) is generated by \((1,1)\) and \((-2,0)\). That simple linear description immediately suggests the invariant \(|w|_a-|w|_b \pmod{2}\), which is the key to classifying equivalence classes and answering all the membership/reachability questions above.

\bigskip

If you want, I can (a) write out an explicit full expansion+swap sequence that builds the long target from \(\texttt{ba}\) in question (3), or (b) produce a tiny diagram illustrating the two equivalence classes and typical representatives. Which would you prefer?

### Exercise 7

Consider the rewrite rules

        ab -> a
        bb -> b
        aa -> b
        
plus rules saying that the order of letters does not matter. 

- Think of `a` and `b` as colours and an [urn](https://en.wikipedia.org/wiki/Urn_problem) that has balls of colour `a` ("white") and `b` ("black"). Interpret the rewrite rules as rules about drawing balls from the urn.
- If you start with 198 black balls and 99 white balls, what is the colour of the last ball remaining? 
- Answer the question above with the help of a suitable invariant.
- Use the invariant to show that the system has unique normal forms.
- If you start with $n$ black balls and $m$ white balls, what is the colour of the last ball remaining?

\subsection*{Exercise 8}

The rewrite rules are
\[
\texttt{ab}\to\texttt{cc},\qquad
\texttt{ac}\to\texttt{bb},\qquad
\texttt{bc}\to\texttt{aa},
\]
and we are allowed to permute letters (order doesn't matter), so we can think of configurations just as multisets or triples of counts \((a,b,c)\).  
Start: \((a,b,c)=(15,14,13)\). Total letters \(N=42\) is preserved by every step (each rule consumes two letters and produces two), so any reachable configuration must still sum to \(42\).

We want to know whether we can reach a configuration that has only one kind of letter, i.e.\ \((42,0,0)\), \((0,42,0)\) or \((0,0,42)\).

\bigskip

\textbf{Key invariant )}  
Look at the difference \(a-b\) modulo \(3\). Check how this changes under each rule:

\begin{itemize}
  \item For \(\texttt{ab}\to\texttt{cc}\): \((a,b,c)\) goes to \((a-1,b-1,c+2)\). So
  \[
  (a-1)-(b-1)=a-b,
  \]
  i.e.\ \(a-b\) does not change at all.
  \item For \(\texttt{ac}\to\texttt{bb}\): \((a,b,c)\mapsto(a-1,b+2,c-1)\). So
  \[
  (a-1)-(b+2)=a-b-3,
  \]
  i.e.\ \(a-b\) changes by \(-3\).
  \item For \(\texttt{bc}\to\texttt{aa}\): \((a,b,c)\mapsto(a+2,b-1,c-1)\). So
  \[
  (a+2)-(b-1)=a-b+3,
  \]
  i.e.\ \(a-b\) changes by \(+3\).
\end{itemize}

So every rule changes \(a-b\) by a multiple of \(3\). That means the value of \(a-b\) modulo \(3\) is an invariant of the system.

\bigskip

\textbf{Apply the invariant to the start and targets.}  
Compute the invariant for the start:
\[
a-b = 15-14 = 1 \equiv 1 \pmod{3}.
\]
For the three all-one-letter targets we have
\[
(42,0,0):\ a-b=42\equiv 0\pmod{3},\quad
(0,42,0):\ a-b=-42\equiv 0\pmod{3},\quad
(0,0,42):\ a-b=0\equiv 0\pmod{3}.
\]
Every all-one-letter configuration has \(a-b\equiv 0\pmod{3}\), but our start has \(a-b\equiv 1\pmod{3}\). Since \(a-b\pmod{3}\) is invariant, it is impossible to reach any of the all-one-letter targets from \((15,14,13)\).

\bigskip

\textbf{Conclusion.}  
No — starting from \(15\) \texttt{a}'s, \(14\) \texttt{b}'s and \(13\) \texttt{c}'s you \emph{cannot} reach a configuration with only \texttt{a}'s, only \texttt{b}'s, or only \texttt{c}'s. The invariant \(a-b\pmod{3}\) (which equals \(1\) at the start) rules those targets out (they all have value \(0\) modulo \(3\)).

\subsection*{Exercise 9}

We work over the alphabet \(\{O,R,K\}\).  
Write \(x\) for an arbitrary string over \(\{O,R,K\}^*\). The four rules in a precise ARS form are:

\[
\begin{aligned}
&(1)\quad &uR &\longrightarrow uRK &\qquad&\text{(if the last letter is \(R\) you may add a \(K\) at the end)}\\
&(2)\quad &Ox &\longrightarrow Oxx &\qquad&\text{(if a word begins with \(O\) and has tail \(x\), duplicate the tail)}\\
&(3)\quad &u\,RRR\,v &\longrightarrow uKv &\qquad&\text{(replace any occurrence of \(RRR\) by \(K\))}\\
&(4)\quad &u\,KK\,v &\longrightarrow u v &\qquad&\text{(erase any occurrence of \(KK\))}
\end{aligned}
\]

Here \(u,v\) are arbitrary context strings in \(\{O,R,K\}^*\) and rule (2) is intended to apply when the whole word has the form \(Ox\) (i.e.\ \(O\) is the first letter). This describes the ARS \((A,\to)\) where \(A=\{O,R,K\}^*\) and \(\to\) is the relation generated by the four schemes above.

\bigskip

\textbf{Some sample reductions.}  
I'll show a few short reductions so you get a feel for the rules.

\[
\begin{aligned}
&\text{(a) }OK \xrightarrow{\text{(2) with }x=K} OKK \xrightarrow{\text{(4)}} O.\\[4pt]
&\text{(b) }OR \xrightarrow{\text{(1)}} ORK \xrightarrow{\text{(2) with }x=RK} ORKRK
          \xrightarrow{\text{(2) with }x=RKRK} ORKRKRKRK \ \text{(and so on, tails can blow up).}\\[4pt]
&\text{(c) }ORRR \xrightarrow{\text{(3)}} OK \quad\text{(because the substring \(RRR\) becomes \(K\)).}
\end{aligned}
\]

Note (c): if you already have three consecutive \(R\)'s anywhere you can collapse them to a single \(K\).

\bigskip

\textbf{Question: Can we reduce \(\texttt{OK}\) to \(\texttt{OR}\)?}  

No. The easy reason is that \(\texttt{OK}\) contains zero \(R\)'s, and none of the four rules can create an \(R\) out of nothing:

\begin{itemize}
  \item Rule (1) only appends a \(K\) when there is already an \(R\) at the end — it does not create new \(R\)'s.
  \item Rule (2) duplicates the tail \(x\), so it only copies letters already present; it does not introduce new letters of types not already in \(x\).
  \item Rule (3) replaces three \(R\)'s by a single \(K\) (it removes \(R\)'s, never adds them).
  \item Rule (4) erases \(KK\) (it only removes \(K\)'s).
\end{itemize}

So starting from \(OK\) the number of \(R\)'s is always \(0\). Since \(\texttt{OR}\) has one \(R\), \(\texttt{OK}\not\to^{*}\texttt{OR}\).

\bigskip

\textbf{Question: Can we reduce \(\texttt{OR}\) to \(\texttt{OK}\)?}  

No — and here a simple invariant proves impossibility.

Let \(r(w)\) denote the number of \(R\)'s in a word \(w\). Track how \(r\) changes under each rule:

\begin{itemize}
  \item (1) \(uR\to uRK\): \(r\) is unchanged.
  \item (2) \(Ox\to Oxx\): if the word is \(Ox\) and \(x\) contains \(r_x\) many \(R\)'s, then after the rule the word is \(Oxx\) and the number of \(R\)'s becomes \(2r_x\). So rule (2) multiplies the count of \(R\)'s in the tail
\subsection*{Exercise 10}

\textbf{Setup.}  
We have a box containing some black and white balls. A step is: remove any one ball; if the removed ball is black then (after removing it) you may add any finite number of white balls. We need to show that every possible sequence of such steps eventually stops (i.e.\ the process always terminates).

\bigskip

\textbf{Idea (student-style).}  
The only thing that can be added to the box are white balls, and the only way to change the number of black balls is to remove them (you never add black balls). Intuitively that suggests the number of black balls will eventually run out if we keep removing them often enough; but we must also handle the fact that removing a black can add arbitrarily many whites, which could allow infinitely many further removals of whites. The right way to make this rigorous is to pick a measure (an ordering) on configurations that always strictly decreases with each move and that has no infinite descending chains. A lexicographic order on the pair \((\#\text{black},\#\text{white})\) does exactly that.

\bigskip

\textbf{Formal argument.}

Describe a configuration by the pair \((B,W)\) where \(B\) is the number of black balls and \(W\) the number of white balls (both are natural numbers).

Order these pairs lexicographically, with \(B\) the primary coordinate and \(W\) the secondary one:
\[
(B_1,W_1) \;>\; (B_2,W_2)
\quad\Longleftrightarrow\quad
\big(B_1>B_2\big)\ \text{ or }\ \big(B_1=B_2\ \text{and}\ W_1>W_2\big).
\]
(So we compare first by how many black balls there are; if those are equal we compare by how many white balls there are.)

This order is well-founded: any strictly decreasing sequence \((B_0,W_0) > (B_1,W_1) > (B_2,W_2) > \cdots\) must have strictly decreasing \(B\)'s eventually (because \(B\) cannot stay constant forever while \(W\) strictly decreases indefinitely as \(W\) is a natural number). Since \(B\) is a natural number it cannot decrease infinitely many times, so infinite descending chains are impossible.

Now check that every allowed move strictly decreases \((B,W)\) in this lexicographic order:

\begin{itemize}
  \item If you remove a white ball, then \(B\) stays the same and \(W\) decreases by \(1\). Thus \((B,W)\) goes to \((B,W-1)\), which is strictly smaller (same \(B\), smaller \(W\)).
  \item If you remove a black ball, then \(B\) decreases by \(1\). After removing the black you may add some finite number \(k\ge 0\) of white balls, so the new configuration is \((B-1,\,W+k)\). Even though \(W+k\) could be larger than the old \(W\), the first coordinate \(B-1\) is strictly smaller than \(B\). Hence \((B-1,W+k)\) is strictly smaller than \((B,W)\) in the lexicographic order (because the primary coordinate decreased).
\end{itemize}

So every possible move produces a strictly smaller pair \((B',W')\) under our well-founded order. Therefore no infinite sequence of moves is possible and every sequence of moves must eventually terminate.

\bigskip

\textbf{Conclusion.}  
Using the lexicographic order on the pair \((\#\text{black},\#\text{white})\) as a measure shows that every allowed move strictly decreases the configuration and this order has no infinite descending chains. Hence the process always terminates.

\bigskip

\textbf{Remark / example.}  
If we start with \((B,W)=(3,0)\), possible moves might be
\[
(3,0)\to(2,5)\ \text{(removed a black, added 5 whites)}\to(2,4)\to(2,0)\to(1,0)\to(0,0),
\]
and each arrow is a decrease in the lexicographic order (first coordinate falls from \(3\) to \(2\), then whites drop while blacks stay \(2\), etc.), so the chain must stop.
\subsection*{Exercise 10}

\textbf{Setup.}  
We have a box containing some black and white balls. A step is: remove any one ball; if the removed ball is black then (after removing it) you may add any finite number of white balls. We need to show that every possible sequence of such steps eventually stops (i.e.\ the process always terminates).

\bigskip

\textbf{Idea.}  
The only thing that can be added to the box are white balls, and the only way to change the number of black balls is to remove them (you never add black balls). Intuitively that suggests the number of black balls will eventually run out if we keep removing them often enough; but we must also handle the fact that removing a black can add arbitrarily many whites, which could allow infinitely many further removals of whites. The right way to make this rigorous is to pick a measure (an ordering) on configurations that always strictly decreases with each move and that has no infinite descending chains. A lexicographic order on the pair \((\#\text{black},\#\text{white})\) does exactly that.

\textbf{Conclusion.}  
Using the order on the pair \((\#\text{black},\#\text{white})\) as a measure shows that every allowed move strictly decreases the configuration and this order has no infinite descending chains. Hence the process always terminates.

\bigskip

\textbf{Remark / example.}  
If we start with \((B,W)=(3,0)\), possible moves might be
\[
(3,0)\to(2,5)\ \text{(removed a black, added 5 whites)}\to(2,4)\to(2,0)\to(1,0)\to(0,0),
\]
and each arrow is a decrease in the lexicographic order (first coordinate falls from \(3\) to \(2\), then whites drop while blacks stay \(2\), etc.), so the chain must stop.

\end{document}
